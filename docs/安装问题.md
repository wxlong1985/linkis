1. 根据官方进行编绎 参考链接https://linkis.apache.org/zh-CN/docs/1.4.0/development/build
2. 修改bin/start-all.sh.sh 的 startDssWeb 的nginx启动为 ngins -s reload  以免影响整个nginx
2. conf/db.sh config.sh
3. 执行bin/install.sh
3. dss/conf/dss-server.properties
8. linkis/conf/config.sh db.sh
4. linkis/conf/linkis.properties
```shell
wds.linkis.bml.hdfs.prefix=hdfs:///opt/module/dss_linkis/tmp/linkis
该配置默认以hdfs://开头 务必要去除
```
5. linkis/conf/linkis-env.sh
6. linkis/conf/linkis-mg-gateway.properties
7. linkis/conf/linkis-ps-publicservice.properties



### 出现问题及对应解决方式
HADOOP_CONFIG_DIR没找到
HIVE_CONFIG_DIR没找到
需要配置环境变量如下，这里不明白，为什么
export HADOOP_CONF_DIR=/opt/module/hadoop-3.2.4/etc/hadoop/
export HIVE_CONF_DIR=/opt/module/apache-hive-3.1.2-bin/config/

判断代码在org.apache.linkis.ecm.core.launch.ProcessEngineConnLaunch.launch这个方法里面
CommonVars读取变量没找到。CommonVars源码有从linkis.properties里面去读取。该文件也有配置。为什么读取不到？




linkis1.4.0
org.apache.linkis.engineplugin.server.service.DefaultEngineConnResourceService.getEngineConnBMLResources
linkis.engineconn.bml.version.may.with.prefix  配置为false  或者修改代码